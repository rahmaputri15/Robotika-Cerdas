{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJp-D51g0IDd"
      },
      "source": [
        "## **1) Importing Python Packages for GAN**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k5mFBuzzl2a"
      },
      "source": [
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Import LeakyReLU directly from keras.layers\n",
        "from keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "!mkdir generated_images"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Potongan kode di atas berfungsi untuk **mengimpor library dan menyiapkan direktori kerja** yang dibutuhkan dalam proyek *deep learning*, khususnya pada implementasi **Generative Adversarial Network (GAN)**. Library **Keras** digunakan untuk membangun arsitektur jaringan saraf tiruan melalui kelas-kelas seperti `Sequential`, `Dense`, `Conv2D`, dan `Conv2DTranspose`, yang berperan dalam membentuk generator maupun discriminator. Lapisan **LeakyReLU** diimpor untuk mengatasi masalah *dying ReLU* dengan memberikan gradien kecil pada nilai negatif, sementara **Dropout** membantu mencegah *overfitting*. Optimizer **Adam** digunakan untuk mempercepat proses konvergensi selama pelatihan model dengan pengaturan *learning rate* adaptif. Selain itu, library **NumPy** digunakan untuk pengolahan data numerik seperti manipulasi vektor laten. Baris terakhir `!mkdir generated_images` digunakan untuk membuat folder bernama **generated_images**, yang berfungsi sebagai tempat penyimpanan hasil gambar yang dihasilkan oleh generator selama proses pelatihan.\n"
      ],
      "metadata": {
        "id": "T27f4Onz2h00"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-eZOzg0X79"
      },
      "source": [
        "## **2) Parameters for Neural Networks & Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RThZMDruz9cB"
      },
      "source": [
        "img_width = 32\n",
        "img_height = 32\n",
        "channels = 3\n",
        "img_shape = (img_width, img_height, channels)\n",
        "latent_dim = 100\n",
        "adam = Adam(learning_rate=0.0002)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Kode di atas digunakan untuk **mendefinisikan parameter dasar** dalam membangun model *Generative Adversarial Network (GAN)*. Variabel `img_width`, `img_height`, dan `channels` menentukan ukuran serta format gambar yang akan diproses, yaitu **32x32 piksel dengan 3 saluran warna (RGB)**. Variabel `img_shape` menyatukan ketiga nilai tersebut menjadi satu bentuk tuple yang akan digunakan sebagai **input shape** pada model *discriminator*. Selanjutnya, `latent_dim = 100` menetapkan **dimensi ruang laten** yang berfungsi sebagai input acak bagi *generator* untuk menghasilkan gambar baru. Terakhir, `adam = Adam(learning_rate=0.0002)` mendefinisikan **optimizer Adam** dengan *learning rate* kecil agar proses pelatihan stabil dan konvergen saat memperbarui bobot model generator maupun discriminator.\n"
      ],
      "metadata": {
        "id": "W21lI39R4aAm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3bcJZZg0cqy"
      },
      "source": [
        "## **3) Building Generator**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdiqZpri0iQh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "e78b6760-6458-4d42-86b4-c25b52f46590"
      },
      "source": [
        "def build_generator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Create first layer, to receive the input\n",
        "    model.add(Dense(256 * 4 * 4, input_dim = latent_dim))\n",
        "    # 256 * 8 * 8; for upscaling the layers,\n",
        "    # initial shape to construct into final shape\n",
        "\n",
        "    # Create default activation function\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "    # Create reshape layer\n",
        "    model.add(Reshape((4, 4,256)))\n",
        "    # 8,8,256 ; reffers to first layer\n",
        "\n",
        "    # Adding more layers for neurons and better result\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha= 0.2))\n",
        "    # (4,4) >> filter size\n",
        "    # strides = (2,2) >> Convolutional layers, that how NN understand images\n",
        "\n",
        "    # Create Final output layer and forming image shape\n",
        "    # the shape (3, (3,3)) reffers to image shape :\n",
        "    #    >>>  img_shape = (img_width, img_height, channels)\n",
        "    model.add(Conv2D(3, (3,3), activation= 'tanh', padding = 'same'))\n",
        "\n",
        "    #\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "generator = build_generator()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │       \u001b[38;5;34m413,696\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m524,416\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m3,459\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">413,696</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,459</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,466,115\u001b[0m (5.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> (5.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,466,115\u001b[0m (5.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> (5.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Kode di atas berfungsi untuk **membangun arsitektur generator** dalam model *Generative Adversarial Network (GAN)*, yang bertugas menghasilkan gambar tiruan menyerupai data asli. Model dimulai dengan lapisan **Dense** berukuran besar (4096 neuron) untuk membentuk representasi awal dari *noise* berdimensi 100 yang diberikan sebagai input. Lapisan **LeakyReLU** digunakan untuk menghindari *dead neurons* dengan memberikan sedikit gradien pada nilai negatif. Selanjutnya, lapisan **Reshape** mengubah vektor 1D menjadi bentuk 3D (4×4×256), yang kemudian diperbesar secara bertahap menggunakan tiga lapisan **Conv2DTranspose** agar gambar memiliki ukuran akhir 32×32 piksel. Setiap lapisan transpos konvolusi menggunakan aktivasi **LeakyReLU** agar hasil pembelajaran tetap stabil. Akhirnya, lapisan **Conv2D** dengan aktivasi **tanh** menghasilkan output berukuran (32, 32, 3), yaitu gambar berwarna RGB dalam rentang nilai antara -1 hingga 1. Dengan total **1.466.115 parameter yang dapat dilatih**, generator ini mampu membentuk pola visual kompleks yang mendekati citra asli dalam dataset.\n"
      ],
      "metadata": {
        "id": "9J-SQ8ef46uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UYOcIP5N4daj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt6QsJCW0mcI"
      },
      "source": [
        "## **4) Building Discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2JzEAPv0lKt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "87ff5adf-0be6-45eb-e76b-7b90b613e133"
      },
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    # Create input layer and filter and stride layer. That makes NN understand image\n",
        "    model.add(Conv2D(64, (3,3), padding = 'same', input_shape = img_shape))\n",
        "\n",
        "    # Adding activation function\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(128, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Conv2D(256, (3,3), padding = 'same'))\n",
        "    model.add(LeakyReLU(alpha = 0.2))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Create output layer\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m262,145\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,145</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m780,545\u001b[0m (2.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> (2.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m780,545\u001b[0m (2.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> (2.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Kode di atas berfungsi untuk **membangun arsitektur *discriminator*** pada model *Generative Adversarial Network (GAN)*, yang bertugas menilai apakah suatu gambar merupakan hasil nyata dari dataset atau gambar palsu hasil generator. Model ini menggunakan beberapa lapisan **Conv2D** untuk mengekstraksi fitur visual dari gambar berukuran 32×32 piksel, dengan aktivasi **LeakyReLU (α = 0.2)** agar pembelajaran tetap stabil dan tidak kehilangan informasi negatif. Setiap lapisan konvolusi meningkatkan jumlah filter (dari 64 hingga 256) untuk menangkap pola gambar yang semakin kompleks. Setelah fitur diekstraksi, data diratakan dengan **Flatten** dan sebagian neuron dinonaktifkan menggunakan **Dropout (0.4)** guna mengurangi risiko *overfitting*. Lapisan akhir berupa **Dense (1 neuron)** dengan aktivasi **sigmoid** menghasilkan probabilitas antara 0 dan 1 yang menunjukkan seberapa besar kemungkinan gambar tersebut nyata. Total terdapat **780.545 parameter trainable**, dan model ini dikompilasi menggunakan *binary crossentropy* sebagai *loss function* serta *Adam optimizer* untuk proses pembelajaran yang efisien.\n"
      ],
      "metadata": {
        "id": "_muJYFy_48X5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbcKcKmA0q2S"
      },
      "source": [
        "## **5) Connecting Neural Networks to build GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0Ue3TEd0xLy"
      },
      "source": [
        "GAN = Sequential()\n",
        "discriminator.trainable = False\n",
        "GAN.add(generator)\n",
        "GAN.add(discriminator)\n",
        "\n",
        "GAN.compile(loss='binary_crossentropy', optimizer=adam)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPqU8dZDaQmE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "31120d00-57e6-4b3f-e012-815982aae79d"
      },
      "source": [
        "GAN.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │     \u001b[38;5;34m1,466,115\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │       \u001b[38;5;34m780,545\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,246,660\u001b[0m (8.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,246,660</span> (8.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,466,115\u001b[0m (5.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,466,115</span> (5.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m780,545\u001b[0m (2.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,545</span> (2.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Kode di atas berfungsi untuk **menggabungkan generator dan discriminator menjadi satu model utuh bernama GAN (Generative Adversarial Network)**. Pada tahap ini, **discriminator dibuat tidak dapat dilatih (trainable=False)** agar selama proses pelatihan, hanya generator yang diperbarui bobotnya berdasarkan umpan balik dari discriminator. Model GAN menerima input berupa **vektor laten berdimensi 100**, yang kemudian diubah oleh **generator** menjadi gambar berukuran **32×32 piksel dengan 3 saluran warna (RGB)**. Gambar hasil tersebut langsung diteruskan ke **discriminator** untuk dinilai apakah termasuk gambar nyata atau palsu. Model ini dikompilasi menggunakan **loss function binary crossentropy** dan **optimizer Adam** untuk mempercepat konvergensi pelatihan. Dari hasil ringkasan model, total terdapat **2.246.660 parameter**, di mana **1.466.115 parameter dapat dilatih** (milik generator) dan **780.545 parameter tidak dapat dilatih** (milik discriminator), menunjukkan bahwa hanya generator yang belajar menghasilkan gambar semakin realistis selama proses pelatihan.\n"
      ],
      "metadata": {
        "id": "tAr-wEeu495R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WaNhBDwRwTG"
      },
      "source": [
        "## **6) Outputting Images**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEJ0WbjRppy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import imageio\n",
        "import PIL\n",
        "\n",
        "save_name = 0.00000000\n",
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    global save_name\n",
        "    save_name += 0.00000001\n",
        "    # print(\"%.8f\" % save_name)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    # gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    gen_imgs = (gen_imgs + 1) / 2.0\n",
        "    # gen_imgs = gen_imgs * 255\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt])\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"generated_images/%.8f.png\" % save_name)\n",
        "    plt.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Kode di atas berfungsi untuk **menyimpan hasil gambar yang dihasilkan oleh generator selama proses pelatihan GAN** dalam bentuk grid berukuran **5×5 gambar** (total 25 gambar per epoch). Fungsi `save_imgs(epoch)` dimulai dengan membuat **noise acak (vektor laten)** berdimensi 100, yang kemudian dimasukkan ke **model generator** untuk menghasilkan gambar sintetis. Hasil keluaran generator berada dalam rentang nilai **-1 hingga 1**, sehingga dilakukan **rescaling** menggunakan `(gen_imgs + 1) / 2.0` agar berada pada rentang **0–1**, sesuai dengan format tampilan gambar. Setiap gambar hasil prediksi kemudian ditampilkan dalam grid menggunakan `matplotlib` dan disimpan ke folder `generated_images` dengan **nama file unik berdasarkan nilai variabel `save_name`**, yang terus bertambah setiap kali fungsi dijalankan. Dengan cara ini, pengguna dapat melihat perkembangan kualitas gambar yang dihasilkan generator dari waktu ke waktu selama pelatihan GAN berlangsung.\n"
      ],
      "metadata": {
        "id": "uA63Olor4_O2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE57Lk5V0xs2"
      },
      "source": [
        "## **7) Training GAN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size = 32, save_interval = 500, data_limit=1000):\n",
        "    (X_train, _), (_, _) = cifar10.load_data()\n",
        "\n",
        "    # Rescaling the data\n",
        "    X_train = X_train / 127.5 -1.\n",
        "\n",
        "    # Jika data_limit diberikan, batasi jumlah data yang digunakan\n",
        "    if data_limit is not None:\n",
        "        X_train = X_train[:data_limit]\n",
        "\n",
        "    bat_per_epo = int(X_train.shape[0] / batch_size)\n",
        "\n",
        "    # Create Y label for NN\n",
        "    valid = np.ones((batch_size,1))\n",
        "    fakes = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for j in range(bat_per_epo):\n",
        "            # Get Random Batch\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            # Generate Fake Images\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            gen_imgs = generator.predict(noise)\n",
        "\n",
        "            # Train Discriminator\n",
        "            d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = discriminator.train_on_batch(gen_imgs, fakes)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "            # Inverse Y label\n",
        "            g_loss = GAN.train_on_batch(noise, valid)\n",
        "\n",
        "            # Correctly format the output using elements of d_loss\n",
        "            print(\"******* %d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "        save_imgs(epoch)\n",
        "\n",
        "# Batas data menjadi 1000 gambar\n",
        "train(epochs=10, batch_size=32, save_interval=500, data_limit=1000) #original code: train(epochs=1000, batch_size=64, save_interval=200)"
      ],
      "metadata": {
        "id": "LJc1MkJV7OVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b60df5a-a7a1-4dd8-f36d-8e044ef4a49e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 0 [D loss: 0.683439, acc: 48.55%] [G loss: 0.691496]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 0 [D loss: 0.683008, acc: 48.16%] [G loss: 0.690784]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 0 [D loss: 0.683345, acc: 47.64%] [G loss: 0.689919]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 0 [D loss: 0.683870, acc: 47.29%] [G loss: 0.688894]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 0 [D loss: 0.684416, acc: 46.82%] [G loss: 0.687700]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 0 [D loss: 0.684983, acc: 46.47%] [G loss: 0.686361]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 0 [D loss: 0.685762, acc: 46.18%] [G loss: 0.684706]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 0 [D loss: 0.686533, acc: 45.96%] [G loss: 0.682699]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 0 [D loss: 0.687827, acc: 45.63%] [G loss: 0.680413]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 0 [D loss: 0.689210, acc: 45.36%] [G loss: 0.677776]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 0 [D loss: 0.690993, acc: 45.01%] [G loss: 0.674718]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 0 [D loss: 0.692752, acc: 45.14%] [G loss: 0.671140]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 0 [D loss: 0.694652, acc: 44.95%] [G loss: 0.667148]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 0 [D loss: 0.696702, acc: 45.07%] [G loss: 0.662800]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 0 [D loss: 0.698940, acc: 45.26%] [G loss: 0.658321]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 0 [D loss: 0.701533, acc: 45.17%] [G loss: 0.653487]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "******* 0 [D loss: 0.704433, acc: 44.94%] [G loss: 0.648584]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "******* 0 [D loss: 0.707584, acc: 44.74%] [G loss: 0.643530]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "******* 0 [D loss: 0.710702, acc: 44.69%] [G loss: 0.638286]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "******* 0 [D loss: 0.713895, acc: 44.44%] [G loss: 0.633264]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "******* 0 [D loss: 0.717049, acc: 44.22%] [G loss: 0.628172]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "******* 0 [D loss: 0.720305, acc: 44.20%] [G loss: 0.623005]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "******* 0 [D loss: 0.723642, acc: 44.24%] [G loss: 0.617582]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "******* 0 [D loss: 0.727091, acc: 44.05%] [G loss: 0.612619]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 0 [D loss: 0.730443, acc: 44.15%] [G loss: 0.607729]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "******* 0 [D loss: 0.733727, acc: 44.13%] [G loss: 0.602856]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 0 [D loss: 0.736894, acc: 44.17%] [G loss: 0.598253]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "******* 0 [D loss: 0.739992, acc: 44.06%] [G loss: 0.593879]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "******* 0 [D loss: 0.743013, acc: 43.95%] [G loss: 0.589472]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 0 [D loss: 0.746047, acc: 43.75%] [G loss: 0.585286]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 0 [D loss: 0.749125, acc: 43.75%] [G loss: 0.581174]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 1 [D loss: 0.752096, acc: 43.75%] [G loss: 0.576951]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.755129, acc: 43.71%] [G loss: 0.572897]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.758085, acc: 43.54%] [G loss: 0.568864]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 1 [D loss: 0.760940, acc: 43.50%] [G loss: 0.564951]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.763934, acc: 43.39%] [G loss: 0.561278]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.766708, acc: 43.52%] [G loss: 0.557394]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 1 [D loss: 0.769578, acc: 43.41%] [G loss: 0.553729]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 1 [D loss: 0.772318, acc: 43.34%] [G loss: 0.550116]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.775054, acc: 43.31%] [G loss: 0.546630]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.777827, acc: 43.39%] [G loss: 0.543187]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.780376, acc: 43.54%] [G loss: 0.539644]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.783104, acc: 43.31%] [G loss: 0.536245]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.785840, acc: 43.35%] [G loss: 0.533029]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 1 [D loss: 0.788494, acc: 43.39%] [G loss: 0.529811]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.790979, acc: 43.46%] [G loss: 0.526479]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 1 [D loss: 0.793521, acc: 43.44%] [G loss: 0.523539]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.796131, acc: 43.32%] [G loss: 0.520436]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 1 [D loss: 0.798708, acc: 43.33%] [G loss: 0.517490]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.801292, acc: 43.25%] [G loss: 0.514535]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 1 [D loss: 0.803848, acc: 43.23%] [G loss: 0.511686]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 1 [D loss: 0.806282, acc: 43.18%] [G loss: 0.508856]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.808669, acc: 43.08%] [G loss: 0.506030]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "******* 1 [D loss: 0.811001, acc: 43.09%] [G loss: 0.503432]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.813301, acc: 43.02%] [G loss: 0.500739]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.815624, acc: 43.01%] [G loss: 0.498140]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "******* 1 [D loss: 0.817818, acc: 43.02%] [G loss: 0.495543]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 1 [D loss: 0.819986, acc: 43.00%] [G loss: 0.493050]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 1 [D loss: 0.822244, acc: 42.94%] [G loss: 0.490544]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 1 [D loss: 0.824441, acc: 42.93%] [G loss: 0.488144]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 1 [D loss: 0.826581, acc: 42.94%] [G loss: 0.485725]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 1 [D loss: 0.828731, acc: 42.91%] [G loss: 0.483408]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 2 [D loss: 0.830790, acc: 42.94%] [G loss: 0.481108]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.832794, acc: 42.91%] [G loss: 0.478969]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.834742, acc: 42.97%] [G loss: 0.476821]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.836670, acc: 43.02%] [G loss: 0.474743]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.838577, acc: 42.97%] [G loss: 0.472730]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.840381, acc: 42.96%] [G loss: 0.470738]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.842275, acc: 42.94%] [G loss: 0.468692]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.844156, acc: 42.89%] [G loss: 0.466719]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 2 [D loss: 0.846004, acc: 42.78%] [G loss: 0.464702]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.847776, acc: 42.85%] [G loss: 0.462753]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 2 [D loss: 0.849647, acc: 42.76%] [G loss: 0.460923]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.851446, acc: 42.75%] [G loss: 0.459075]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 2 [D loss: 0.853196, acc: 42.75%] [G loss: 0.457295]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.854909, acc: 42.74%] [G loss: 0.455589]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.856593, acc: 42.71%] [G loss: 0.453819]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.858257, acc: 42.72%] [G loss: 0.452100]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.859987, acc: 42.79%] [G loss: 0.450415]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.861671, acc: 42.81%] [G loss: 0.448792]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.863229, acc: 42.76%] [G loss: 0.447151]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 2 [D loss: 0.864737, acc: 42.75%] [G loss: 0.445589]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.866306, acc: 42.78%] [G loss: 0.444053]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.867845, acc: 42.67%] [G loss: 0.442500]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 2 [D loss: 0.869283, acc: 42.66%] [G loss: 0.441007]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 2 [D loss: 0.870744, acc: 42.69%] [G loss: 0.439559]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 2 [D loss: 0.872245, acc: 42.72%] [G loss: 0.438071]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "******* 2 [D loss: 0.873652, acc: 42.79%] [G loss: 0.436609]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.875068, acc: 42.75%] [G loss: 0.435137]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.876507, acc: 42.72%] [G loss: 0.433739]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.877931, acc: 42.68%] [G loss: 0.432353]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.879379, acc: 42.65%] [G loss: 0.430957]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 2 [D loss: 0.880759, acc: 42.64%] [G loss: 0.429561]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.882053, acc: 42.62%] [G loss: 0.428254]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 3 [D loss: 0.883395, acc: 42.65%] [G loss: 0.426973]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 3 [D loss: 0.884719, acc: 42.67%] [G loss: 0.425632]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.886011, acc: 42.67%] [G loss: 0.424359]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 3 [D loss: 0.887295, acc: 42.66%] [G loss: 0.423054]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.888583, acc: 42.66%] [G loss: 0.421801]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 3 [D loss: 0.889833, acc: 42.69%] [G loss: 0.420597]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.891093, acc: 42.65%] [G loss: 0.419397]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.892311, acc: 42.63%] [G loss: 0.418175]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.893523, acc: 42.63%] [G loss: 0.417030]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.894780, acc: 42.55%] [G loss: 0.415869]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 3 [D loss: 0.895973, acc: 42.55%] [G loss: 0.414752]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.897174, acc: 42.49%] [G loss: 0.413614]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 3 [D loss: 0.898360, acc: 42.47%] [G loss: 0.412520]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.899479, acc: 42.51%] [G loss: 0.411450]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.900540, acc: 42.51%] [G loss: 0.410372]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 3 [D loss: 0.901589, acc: 42.52%] [G loss: 0.409312]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 3 [D loss: 0.902661, acc: 42.51%] [G loss: 0.408209]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 3 [D loss: 0.903698, acc: 42.54%] [G loss: 0.407162]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 3 [D loss: 0.904770, acc: 42.55%] [G loss: 0.406143]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "******* 3 [D loss: 0.905800, acc: 42.55%] [G loss: 0.405125]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "******* 3 [D loss: 0.906823, acc: 42.57%] [G loss: 0.404142]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "******* 3 [D loss: 0.907896, acc: 42.59%] [G loss: 0.403155]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 3 [D loss: 0.908952, acc: 42.62%] [G loss: 0.402206]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "******* 3 [D loss: 0.909983, acc: 42.61%] [G loss: 0.401234]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "******* 3 [D loss: 0.911020, acc: 42.60%] [G loss: 0.400297]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 3 [D loss: 0.912014, acc: 42.63%] [G loss: 0.399379]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "******* 3 [D loss: 0.912988, acc: 42.60%] [G loss: 0.398478]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "******* 3 [D loss: 0.913950, acc: 42.61%] [G loss: 0.397554]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "******* 3 [D loss: 0.914936, acc: 42.58%] [G loss: 0.396659]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "******* 3 [D loss: 0.915902, acc: 42.58%] [G loss: 0.395799]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 4 [D loss: 0.916893, acc: 42.58%] [G loss: 0.394899]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.917880, acc: 42.57%] [G loss: 0.394031]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.918817, acc: 42.57%] [G loss: 0.393172]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.919771, acc: 42.58%] [G loss: 0.392300]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 4 [D loss: 0.920686, acc: 42.56%] [G loss: 0.391445]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.921566, acc: 42.58%] [G loss: 0.390595]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 4 [D loss: 0.922455, acc: 42.58%] [G loss: 0.389750]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.923333, acc: 42.61%] [G loss: 0.388901]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.924178, acc: 42.62%] [G loss: 0.388095]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.925058, acc: 42.61%] [G loss: 0.387267]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 4 [D loss: 0.925895, acc: 42.62%] [G loss: 0.386493]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 4 [D loss: 0.926756, acc: 42.65%] [G loss: 0.385696]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.927584, acc: 42.67%] [G loss: 0.384919]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.928424, acc: 42.71%] [G loss: 0.384123]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 4 [D loss: 0.929327, acc: 42.70%] [G loss: 0.383383]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 4 [D loss: 0.930202, acc: 42.71%] [G loss: 0.382610]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 4 [D loss: 0.931009, acc: 42.72%] [G loss: 0.381854]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.931816, acc: 42.71%] [G loss: 0.381122]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.932633, acc: 42.72%] [G loss: 0.380410]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.933411, acc: 42.73%] [G loss: 0.379701]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 4 [D loss: 0.934201, acc: 42.71%] [G loss: 0.378999]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "******* 4 [D loss: 0.935012, acc: 42.72%] [G loss: 0.378280]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.935777, acc: 42.70%] [G loss: 0.377574]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.936544, acc: 42.66%] [G loss: 0.376883]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.937291, acc: 42.67%] [G loss: 0.376219]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.938051, acc: 42.69%] [G loss: 0.375527]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 4 [D loss: 0.938828, acc: 42.70%] [G loss: 0.374863]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 4 [D loss: 0.939557, acc: 42.71%] [G loss: 0.374192]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 4 [D loss: 0.940281, acc: 42.70%] [G loss: 0.373528]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 4 [D loss: 0.941025, acc: 42.72%] [G loss: 0.372907]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 4 [D loss: 0.941762, acc: 42.73%] [G loss: 0.372256]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.942510, acc: 42.73%] [G loss: 0.371605]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.943246, acc: 42.69%] [G loss: 0.370975]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.943950, acc: 42.69%] [G loss: 0.370319]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.944625, acc: 42.71%] [G loss: 0.369699]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 5 [D loss: 0.945333, acc: 42.70%] [G loss: 0.369068]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.946028, acc: 42.71%] [G loss: 0.368459]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.946724, acc: 42.73%] [G loss: 0.367855]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.947410, acc: 42.73%] [G loss: 0.367224]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 5 [D loss: 0.948083, acc: 42.73%] [G loss: 0.366644]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.948741, acc: 42.74%] [G loss: 0.366050]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.949402, acc: 42.77%] [G loss: 0.365447]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.950067, acc: 42.77%] [G loss: 0.364839]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.950723, acc: 42.77%] [G loss: 0.364273]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.951351, acc: 42.77%] [G loss: 0.363672]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.952003, acc: 42.76%] [G loss: 0.363104]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 5 [D loss: 0.952696, acc: 42.76%] [G loss: 0.362558]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.953332, acc: 42.77%] [G loss: 0.362006]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 5 [D loss: 0.953942, acc: 42.79%] [G loss: 0.361459]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.954586, acc: 42.79%] [G loss: 0.360912]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.955239, acc: 42.79%] [G loss: 0.360383]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.955879, acc: 42.77%] [G loss: 0.359840]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.956500, acc: 42.77%] [G loss: 0.359305]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.957108, acc: 42.79%] [G loss: 0.358779]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 5 [D loss: 0.957684, acc: 42.80%] [G loss: 0.358275]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 5 [D loss: 0.958266, acc: 42.80%] [G loss: 0.357783]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 5 [D loss: 0.958853, acc: 42.81%] [G loss: 0.357262]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 5 [D loss: 0.959436, acc: 42.78%] [G loss: 0.356763]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 5 [D loss: 0.959997, acc: 42.80%] [G loss: 0.356277]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 5 [D loss: 0.960560, acc: 42.80%] [G loss: 0.355760]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 5 [D loss: 0.961116, acc: 42.80%] [G loss: 0.355252]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 5 [D loss: 0.961655, acc: 42.80%] [G loss: 0.354769]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 6 [D loss: 0.962200, acc: 42.81%] [G loss: 0.354288]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.962768, acc: 42.82%] [G loss: 0.353797]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.963356, acc: 42.81%] [G loss: 0.353309]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.963947, acc: 42.79%] [G loss: 0.352829]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.964507, acc: 42.80%] [G loss: 0.352361]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 6 [D loss: 0.965082, acc: 42.80%] [G loss: 0.351892]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 6 [D loss: 0.965644, acc: 42.80%] [G loss: 0.351418]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 6 [D loss: 0.966196, acc: 42.79%] [G loss: 0.350942]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 6 [D loss: 0.966700, acc: 42.79%] [G loss: 0.350492]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 6 [D loss: 0.967247, acc: 42.81%] [G loss: 0.350040]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 6 [D loss: 0.967824, acc: 42.82%] [G loss: 0.349585]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "******* 6 [D loss: 0.968357, acc: 42.82%] [G loss: 0.349128]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 6 [D loss: 0.968894, acc: 42.82%] [G loss: 0.348691]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.969426, acc: 42.84%] [G loss: 0.348278]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.969959, acc: 42.84%] [G loss: 0.347833]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 6 [D loss: 0.970480, acc: 42.86%] [G loss: 0.347408]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.970997, acc: 42.88%] [G loss: 0.346951]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 6 [D loss: 0.971510, acc: 42.88%] [G loss: 0.346523]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 6 [D loss: 0.972000, acc: 42.87%] [G loss: 0.346101]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "******* 6 [D loss: 0.972517, acc: 42.85%] [G loss: 0.345670]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 6 [D loss: 0.973021, acc: 42.83%] [G loss: 0.345245]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 6 [D loss: 0.973532, acc: 42.80%] [G loss: 0.344836]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 6 [D loss: 0.973994, acc: 42.81%] [G loss: 0.344429]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 6 [D loss: 0.974461, acc: 42.80%] [G loss: 0.344023]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "******* 6 [D loss: 0.974945, acc: 42.78%] [G loss: 0.343629]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "******* 6 [D loss: 0.975437, acc: 42.78%] [G loss: 0.343236]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 6 [D loss: 0.975924, acc: 42.77%] [G loss: 0.342825]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "******* 6 [D loss: 0.976370, acc: 42.78%] [G loss: 0.342421]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "******* 6 [D loss: 0.976824, acc: 42.80%] [G loss: 0.342037]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "******* 6 [D loss: 0.977284, acc: 42.81%] [G loss: 0.341633]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "******* 6 [D loss: 0.977746, acc: 42.81%] [G loss: 0.341259]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "******* 7 [D loss: 0.978213, acc: 42.79%] [G loss: 0.340876]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "******* 7 [D loss: 0.978672, acc: 42.80%] [G loss: 0.340480]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "******* 7 [D loss: 0.979148, acc: 42.80%] [G loss: 0.340096]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 7 [D loss: 0.979619, acc: 42.77%] [G loss: 0.339714]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 7 [D loss: 0.980084, acc: 42.74%] [G loss: 0.339327]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 7 [D loss: 0.980546, acc: 42.73%] [G loss: 0.338969]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 7 [D loss: 0.980998, acc: 42.74%] [G loss: 0.338593]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 7 [D loss: 0.981471, acc: 42.71%] [G loss: 0.338243]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 7 [D loss: 0.981918, acc: 42.72%] [G loss: 0.337876]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 7 [D loss: 0.982356, acc: 42.72%] [G loss: 0.337533]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 7 [D loss: 0.982807, acc: 42.73%] [G loss: 0.337173]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "******* 7 [D loss: 0.983235, acc: 42.75%] [G loss: 0.336808]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 7 [D loss: 0.983674, acc: 42.74%] [G loss: 0.336430]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "******* 7 [D loss: 0.984112, acc: 42.75%] [G loss: 0.336087]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 7 [D loss: 0.984556, acc: 42.74%] [G loss: 0.335719]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "******* 7 [D loss: 0.984972, acc: 42.74%] [G loss: 0.335364]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 7 [D loss: 0.985368, acc: 42.73%] [G loss: 0.335009]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 7 [D loss: 0.985781, acc: 42.74%] [G loss: 0.334652]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 7 [D loss: 0.986215, acc: 42.74%] [G loss: 0.334300]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 7 [D loss: 0.986629, acc: 42.72%] [G loss: 0.333936]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 7 [D loss: 0.987035, acc: 42.71%] [G loss: 0.333595]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 7 [D loss: 0.987444, acc: 42.71%] [G loss: 0.333239]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 7 [D loss: 0.987856, acc: 42.72%] [G loss: 0.332905]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 7 [D loss: 0.988242, acc: 42.71%] [G loss: 0.332573]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 7 [D loss: 0.988643, acc: 42.71%] [G loss: 0.332243]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 7 [D loss: 0.989063, acc: 42.71%] [G loss: 0.331892]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 7 [D loss: 0.989456, acc: 42.71%] [G loss: 0.331550]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 7 [D loss: 0.989848, acc: 42.71%] [G loss: 0.331217]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "******* 7 [D loss: 0.990270, acc: 42.72%] [G loss: 0.330888]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 7 [D loss: 0.990691, acc: 42.71%] [G loss: 0.330569]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 7 [D loss: 0.991093, acc: 42.72%] [G loss: 0.330236]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 8 [D loss: 0.991490, acc: 42.73%] [G loss: 0.329918]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 8 [D loss: 0.991914, acc: 42.72%] [G loss: 0.329593]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 8 [D loss: 0.992334, acc: 42.72%] [G loss: 0.329270]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 8 [D loss: 0.992736, acc: 42.69%] [G loss: 0.328964]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "******* 8 [D loss: 0.993137, acc: 42.67%] [G loss: 0.328655]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 8 [D loss: 0.993532, acc: 42.67%] [G loss: 0.328344]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 0.993927, acc: 42.67%] [G loss: 0.328052]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 0.994327, acc: 42.66%] [G loss: 0.327749]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "******* 8 [D loss: 0.994697, acc: 42.66%] [G loss: 0.327443]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 0.995059, acc: 42.64%] [G loss: 0.327153]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 8 [D loss: 0.995422, acc: 42.63%] [G loss: 0.326831]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 8 [D loss: 0.995806, acc: 42.63%] [G loss: 0.326542]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 8 [D loss: 0.996165, acc: 42.64%] [G loss: 0.326240]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 0.996500, acc: 42.66%] [G loss: 0.325940]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 8 [D loss: 0.996838, acc: 42.68%] [G loss: 0.325651]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "******* 8 [D loss: 0.997191, acc: 42.67%] [G loss: 0.325345]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 0.997559, acc: 42.65%] [G loss: 0.325040]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 0.997908, acc: 42.65%] [G loss: 0.324764]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 8 [D loss: 0.998271, acc: 42.65%] [G loss: 0.324473]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 8 [D loss: 0.998648, acc: 42.64%] [G loss: 0.324207]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 0.999022, acc: 42.63%] [G loss: 0.323917]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 8 [D loss: 0.999380, acc: 42.62%] [G loss: 0.323633]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "******* 8 [D loss: 0.999725, acc: 42.62%] [G loss: 0.323358]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 8 [D loss: 1.000080, acc: 42.60%] [G loss: 0.323092]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "******* 8 [D loss: 1.000440, acc: 42.61%] [G loss: 0.322824]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 8 [D loss: 1.000795, acc: 42.59%] [G loss: 0.322553]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 1.001138, acc: 42.60%] [G loss: 0.322289]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 8 [D loss: 1.001472, acc: 42.60%] [G loss: 0.322015]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 1.001837, acc: 42.57%] [G loss: 0.321745]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 8 [D loss: 1.002197, acc: 42.55%] [G loss: 0.321467]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 8 [D loss: 1.002546, acc: 42.55%] [G loss: 0.321205]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 9 [D loss: 1.002887, acc: 42.53%] [G loss: 0.320940]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.003234, acc: 42.54%] [G loss: 0.320681]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 9 [D loss: 1.003573, acc: 42.56%] [G loss: 0.320426]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.003919, acc: 42.56%] [G loss: 0.320163]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.004244, acc: 42.56%] [G loss: 0.319895]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "******* 9 [D loss: 1.004593, acc: 42.56%] [G loss: 0.319636]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "******* 9 [D loss: 1.004957, acc: 42.56%] [G loss: 0.319391]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 9 [D loss: 1.005308, acc: 42.55%] [G loss: 0.319123]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.005635, acc: 42.54%] [G loss: 0.318877]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "******* 9 [D loss: 1.005943, acc: 42.55%] [G loss: 0.318636]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 9 [D loss: 1.006250, acc: 42.54%] [G loss: 0.318399]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.006566, acc: 42.53%] [G loss: 0.318164]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "******* 9 [D loss: 1.006883, acc: 42.52%] [G loss: 0.317913]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.007183, acc: 42.51%] [G loss: 0.317655]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 9 [D loss: 1.007493, acc: 42.53%] [G loss: 0.317415]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 9 [D loss: 1.007824, acc: 42.50%] [G loss: 0.317164]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "******* 9 [D loss: 1.008147, acc: 42.51%] [G loss: 0.316918]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.008455, acc: 42.51%] [G loss: 0.316664]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 9 [D loss: 1.008755, acc: 42.52%] [G loss: 0.316423]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "******* 9 [D loss: 1.009050, acc: 42.51%] [G loss: 0.316173]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 9 [D loss: 1.009355, acc: 42.51%] [G loss: 0.315927]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 9 [D loss: 1.009653, acc: 42.50%] [G loss: 0.315690]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "******* 9 [D loss: 1.009950, acc: 42.50%] [G loss: 0.315453]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "******* 9 [D loss: 1.010235, acc: 42.50%] [G loss: 0.315218]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.010535, acc: 42.47%] [G loss: 0.314985]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.010838, acc: 42.46%] [G loss: 0.314765]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.011131, acc: 42.46%] [G loss: 0.314524]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "******* 9 [D loss: 1.011427, acc: 42.46%] [G loss: 0.314301]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "******* 9 [D loss: 1.011724, acc: 42.46%] [G loss: 0.314075]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "******* 9 [D loss: 1.012013, acc: 42.45%] [G loss: 0.313858]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "******* 9 [D loss: 1.012312, acc: 42.46%] [G loss: 0.313632]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Kode di atas merupakan **fungsi utama untuk melatih model GAN (Generative Adversarial Network)** menggunakan dataset **CIFAR-10**. Fungsi `train()` bekerja dengan memuat data gambar dari CIFAR-10, lalu melakukan **rescaling nilai piksel dari 0–255 menjadi -1 hingga 1** agar sesuai dengan rentang output generator. Jika diberikan parameter `data_limit`, jumlah data latih akan dibatasi, misalnya hanya 1000 gambar untuk mempercepat proses pelatihan. Dalam setiap epoch, data dibagi menjadi beberapa batch, lalu **discriminator** dilatih dua kali: pertama dengan gambar **asli (label 1)** dan kedua dengan gambar **palsu (label 0)** yang dihasilkan oleh generator. Setelah itu, **generator** dilatih melalui model GAN dengan tujuan **membuat gambar palsu yang mampu menipu discriminator** (dilatih menggunakan label valid/1). Proses ini menghasilkan dua metrik penting: *D loss* (kerugian dan akurasi discriminator) serta *G loss* (kerugian generator). Hasilnya ditampilkan di setiap iterasi, dan pada akhir setiap epoch, fungsi `save_imgs()` dipanggil untuk menyimpan gambar hasil generator, sehingga perkembangan kualitas gambar selama pelatihan dapat diamati secara visual.\n"
      ],
      "metadata": {
        "id": "OlcsnA885A4R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS9wDLeRLUOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da950a27-6fad-4356-b18a-1a20ab90ec8c"
      },
      "source": [
        "noise = np.random.normal(0, 1, (1,latent_dim))\n",
        "gen_imgs = generator.predict(noise)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Baris ini membuat vektor acak (noise) yang menjadi input generator.\n",
        "\n",
        "np.random.normal(0, 1, ...) artinya membuat data acak dari distribusi normal (mean = 0, std = 1).\n",
        "\n",
        "(1, latent_dim) berarti hanya membuat 1 sampel noise dengan panjang vektor sesuai dimensi laten (latent_dim)."
      ],
      "metadata": {
        "id": "RpSzTnAx5Dl0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rlgu8g9Lik9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "352057a2-f6c0-4306-a408-5bc53c927042"
      },
      "source": [
        "gen_imgs = (gen_imgs + 1) / 2.0\n",
        "plt.imshow(gen_imgs[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x790893cc0680>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "plt.imshow(gen_imgs[0]) → membuat objek gambar (itu yang ditampilkan sebagai <matplotlib.image.AxesImage ).\n",
        "\n",
        "plt.show() → benar-benar menampilkan gambar di layar."
      ],
      "metadata": {
        "id": "vxOpqEe05FQe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-jSQoN1Azl"
      },
      "source": [
        "### **8) Making GIF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPShgQpg1EMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb098761-0720-4769-8c5e-5d49ba4ef663"
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "# def display_image(epoch_no):\n",
        "#   return PIL.Image.open('generated_images/%.8f.png'.format(epoch_no))\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('generated_images/*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "\n",
        "  if filenames:  # Check if filenames is not empty\n",
        "    image = imageio.imread(filenames[-1])\n",
        "    writer.append_data(image)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-360815478.py:11: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filename)\n",
            "/tmp/ipython-input-360815478.py:15: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image = imageio.imread(filenames[-1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOGIKA PENJELASAN**\n",
        "Potongan kode di atas digunakan untuk membuat animasi GIF dari seluruh hasil gambar yang telah dihasilkan oleh model GAN selama proses pelatihan. Pertama, kode mengambil semua file gambar .png dari folder generated_images menggunakan glob.glob(), kemudian mengurutkannya agar urutan gambar sesuai dengan proses epoch pelatihan. Setelah itu, dengan bantuan imageio.get_writer(), setiap gambar dibaca menggunakan imageio.imread() dan disusun menjadi satu file GIF bernama dcgan.gif. Proses ini memungkinkan pengguna untuk melihat perkembangan kualitas gambar yang dihasilkan oleh generator dari waktu ke waktu, sehingga memudahkan evaluasi visual terhadap kemajuan pelatihan model GAN."
      ],
      "metadata": {
        "id": "7FRI0iC95Gf0"
      }
    }
  ]
}